[
    {
        "@timestamp": "2021-09-26T07:47:34.234Z",
        "event.dataset": "tidb.tispark",
        "event.module": "tidb",
        "fileset.name": "tispark",
        "input.type": "log",
        "log.flags": [
            "multiline"
        ],
        "log.offset": 0,
        "message": "21/04/14 18:06:53 WARN TaskSetManager: Lost task 12.0 in stage 0.0 (TID 12, 10.142.20.27, executor 1): com.pingcap.tikv.exception.TiClientInternalException: Error reading region:\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.doReadNextRegionChunks(DAGIterator.java:189)\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.readNextRegionChunks(DAGIterator.java:166)\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.hasNext(DAGIterator.java:112)\n\tat org.apache.spark.sql.tispark.TiRowRDD$$anon$1.hasNext(TiRowRDD.scala:69)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.coprocessorrdd_nextBatch_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:232)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.ExecutionException: com.pingcap.tikv.exception.RegionTaskException: Handle region task failed:\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:192)\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.doReadNextRegionChunks(DAGIterator.java:184)\n\t... 18 more\nCaused by: com.pingcap.tikv.exception.RegionTaskException: Handle region task failed:\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.process(DAGIterator.java:233)\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.lambda$submitTasks$1(DAGIterator.java:90)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\t... 3 more\nCaused by: com.pingcap.tikv.exception.SelectException: Execution terminated due to exceeding the deadline\n\tat com.pingcap.tikv.region.RegionStoreClient.doCoprocessor(RegionStoreClient.java:735)\n\tat com.pingcap.tikv.region.RegionStoreClient.handleCopResponse(RegionStoreClient.java:706)\n\tat com.pingcap.tikv.region.RegionStoreClient.coprocess(RegionStoreClient.java:650)\n\tat com.pingcap.tikv.operation.iterator.DAGIterator.process(DAGIterator.java:219)\n\t... 7 more",
        "service.type": "tidb"
    },
    {
        "@timestamp": "2021-09-26T07:47:34.234Z",
        "event.dataset": "tidb.tispark",
        "event.module": "tidb",
        "fileset.name": "tispark",
        "input.type": "log",
        "log.offset": 3266,
        "message": "21/04/14 18:06:58 INFO TaskSetManager: Starting task 12.1 in stage 0.0 (TID 15, 10.142.20.70, executor 0, partition 12, ANY, 12319 bytes)",
        "service.type": "tidb"
    }
]